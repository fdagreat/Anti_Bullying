{"cells":[{"metadata":{},"cell_type":"markdown","source":["<b>Project - Helpline of all sorts</b><br><br>\n","Implimenting LSTM model to predict what the concern is about:<br>\n","0 - work life harassment and stress<br>\n","1 - school bullying related complaints<br>\n","2 - sexual harassment related complaints<br>\n","3 - whistleblowing<br>"]},{"metadata":{"trusted":false},"cell_type":"code","source":["import numpy\n","\n","numpy.random.seed(0)\n","from keras.models import Model\n","from keras.layers import Dense, Input, Dropout, LSTM, Activation\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","from keras.initializers import glorot_uniform\n","numpy.random.seed(1)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a0fbf034a134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n","\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"]}]},{"metadata":{},"cell_type":"markdown","source":["<br><br><b>Converting input sentences into vector word representation, leveraged pre-trained 100-D GloVe embedding.</b>"]},{"metadata":{"trusted":false},"cell_type":"code","source":["import os\n","data_dir = '../Desktop/datasets_and_embeddings/glove.6B.100d.txt'\n","\n","embeddings_index = {}\n","word_to_index = {}\n","index_to_word = {}\n","# f = open(os.path.join(data_dir, 'glove.6B.100d.txt'))\n","f = open(data_dir, encoding=\"utf8\")\n","i = 0\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    word_to_index[word] = i\n","    index_to_word[i] = word\n","    embedding = numpy.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = embedding\n","    i+=1\n","f.close()\n","\n","# for testing purpose to make sure we are getting correct word vectors\n","print('Found %s word vectors.' % len(embeddings_index))\n","print(\"sample embedding of word 'bangalore' is\", embeddings_index['bangalore'])\n","word = \"cucumber\"\n","index = 50000\n","print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n","print(\"the\", str(index+1) + \"th word in the vocabulary is\", index_to_word[index])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<br><br><b>loading the training datsaset</b>"]},{"metadata":{"trusted":false},"cell_type":"code","source":["import csv\n","\n","filename = '../Desktop/datasets_and_embeddings/helpline_datasets.csv'\n","X_train_list = []\n","Y_train_list = []\n","with open(filename,'r',encoding=\"utf-8\") as csvfile:\n","    csvreader = csv.reader(csvfile)\n","    for row in csvreader:\n","        X_train_list.append(row[0])\n","        Y_train_list.append(row[1])\n","            \n","X_train = numpy.array(X_train_list) # converting list into 1-D vector representation   \n","Y_train = numpy.array(Y_train_list) # converting list into 1-D vector representation\n","num_training_sets = 0\n","try:\n","    num_training_sets = numpy.prod(X_train.shape)\n","    print(\"total datasets in training: \",num_training_sets)\n","    if num_training_sets != numpy.prod(X_train.shape):\n","        raise ValueError\n","except ValueError:\n","    print(\"dimensions of datasets won't match, verify once!!!!!\")\n","maxLen = len(max(X_train, key=len).split())\n","index = 9\n","print(\"sample of training set in 9th index: \",X_train[index], Y_train[index])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<br><br><b>Converting array of sentences into array of indices so to feed embeddings() function</b>"]},{"metadata":{"trusted":false},"cell_type":"code","source":["def sentences_to_indices(X, word_to_index, max_len):\n","    m = X.shape[0] #number of training examples\n","    X_indices = numpy.zeros((m, max_len))\n","    for i in range(m):\n","        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n","        sentence_words = X[i].lower().split()\n","        j = 0\n","        for w in sentence_words:\n","            X_indices[i,j] = word_to_index[w]\n","            j = j+1\n","    return X_indices"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["X1 = numpy.array([\"for the past several days I'm suffering from a lot of mental tension due to ongoing audits in office late night\",\n","                 \"I got bullied yesterday from a bunch of senior guys during interval\"])\n","X1_indices = sentences_to_indices(X1,word_to_index, max_length = 21)\n","print(\"X1=\",X1)\n","print(\"X1_indices=\",X1_indices)"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"Python 3.8.2 64-bit","display_name":"Python 3.8.2 64-bit","metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2-final"}},"nbformat":4,"nbformat_minor":1}